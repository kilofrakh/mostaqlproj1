// ------------------------------
// Voice catalog (keep in sync with your ElevenLabs voices)
// ------------------------------
const VOICES = [
  { label: "Aria (Ø£Ø±ÙŠØ§) â€” Ù…ÙˆØµÙ‰ Ø¨Ù‡", voice_id: "9BWtsMINqrJLrRacOk9x", tutor_name: "Ù†ÙˆØ±" },
  { label: "Sarah (Ø³Ø§Ø±Ø©) â€” Ø¯Ø§ÙØ¦",   voice_id: "EXAVITQu4vr4xnSDxMaL", tutor_name: "Ø³Ø§Ø±Ø©" },
  { label: "Laura (Ù„ÙˆØ±Ø§) â€” ÙˆØ§Ø¶Ø­",   voice_id: "FGY2WhTYpPnrIDTdsKH5", tutor_name: "Ù„ÙˆØ±Ø§" },
  { label: "Charlotte (Ø´Ø§Ø±Ù„ÙˆØª) â€” Ø±Ø³Ù…ÙŠ", voice_id: "XB0fDUnXU5powFXDhCwa", tutor_name: "Ø´Ø§Ø±Ù„ÙˆØª" },
];

// ------------------------------
// State
// ------------------------------
let history = []; // [{role, content}]
let mediaRecorder = null;
let chunks = [];

let selected = VOICES[0];

// ------------------------------
// DOM
// ------------------------------
const voiceSelect = document.getElementById("voiceSelect");
const personaHint = document.getElementById("personaHint");
const titleName = document.getElementById("titleName");
const chatEl = document.getElementById("chat");
const recBtn = document.getElementById("recBtn");
const stopBtn = document.getElementById("stopBtn");
const recState = document.getElementById("recState");
const statusEl = document.getElementById("status");
const newChatBtn = document.getElementById("newChatBtn");

// ------------------------------
// Helpers
// ------------------------------
function addMessage(kind, meta, text) {
  const div = document.createElement("div");
  div.className = `msg ${kind}`;
  div.innerHTML = `
    <div class="meta">${meta}</div>
    <div class="text">${escapeHtml(text)}</div>
  `;
  chatEl.appendChild(div);
  chatEl.scrollTop = chatEl.scrollHeight;
}

function escapeHtml(str) {
  return (str || "")
    .replaceAll("&", "&amp;")
    .replaceAll("<", "&lt;")
    .replaceAll(">", "&gt;");
}

function setTutorUI() {
  titleName.textContent = `${selected.tutor_name} â€” Ù…ÙØ¹Ù„ÙÙ‘Ù…Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©`;
  personaHint.textContent = `Ø§Ù„Ø´Ø®ØµÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: ${selected.tutor_name}`;
}

// ------------------------------
// Health check
// ------------------------------
async function loadHealth() {
  try {
    const r = await fetch("/health");
    const j = await r.json();
    statusEl.innerHTML = `
      <span class="badge ${j.groq ? "ok":"no"}">${j.groq ? "âœ…":"âŒ"} Groq</span>
      <span class="badge ${j.eleven ? "ok":"no"}">${j.eleven ? "âœ…":"âŒ"} ElevenLabs</span>
      <div class="hint">Whisper: ${j.whisper.model} (${j.whisper.device})</div>
    `;
  } catch {
    statusEl.innerHTML = `<span class="badge no">âŒ health</span>`;
  }
}

// ------------------------------
// TTS Streaming player via MediaSource (no audio player UI)
// ------------------------------
let ttsSocket = null;
let audioEl = null;
let mediaSource = null;
let sourceBuffer = null;
let queue = [];
let streaming = false;

function ensureAudioPipeline() {
  if (audioEl) return;

  audioEl = document.createElement("audio");
  audioEl.autoplay = true;
  audioEl.muted = false;
  audioEl.style.display = "none";
  document.body.appendChild(audioEl);
}

function resetMediaSource() {
  ensureAudioPipeline();
  queue = [];
  streaming = true;

  mediaSource = new MediaSource();
  audioEl.src = URL.createObjectURL(mediaSource);

  mediaSource.addEventListener("sourceopen", () => {
    // mp3 mime for MSE
    sourceBuffer = mediaSource.addSourceBuffer('audio/mpeg');
    sourceBuffer.mode = "sequence";

    sourceBuffer.addEventListener("updateend", () => {
      if (queue.length > 0 && !sourceBuffer.updating) {
        sourceBuffer.appendBuffer(queue.shift());
      } else if (!streaming && mediaSource.readyState === "open") {
        try { mediaSource.endOfStream(); } catch {}
      }
    });

    // kick off queued buffers
    if (queue.length > 0 && !sourceBuffer.updating) {
      sourceBuffer.appendBuffer(queue.shift());
    }
  });
}

function appendMp3Chunk(chunk) {
  if (!sourceBuffer || sourceBuffer.updating) {
    queue.push(chunk);
    return;
  }
  sourceBuffer.appendBuffer(chunk);
}

// ------------------------------
// Connect TTS websocket
// ------------------------------
function connectTTS() {
  if (ttsSocket && (ttsSocket.readyState === 0 || ttsSocket.readyState === 1)) return;

  const proto = location.protocol === "https:" ? "wss" : "ws";
  ttsSocket = new WebSocket(`${proto}://${location.host}/tts`);
  ttsSocket.binaryType = "arraybuffer";

  ttsSocket.onmessage = (evt) => {
    if (typeof evt.data === "string") {
      // JSON event
      try {
        const j = JSON.parse(evt.data);
        if (j.event === "end") {
          streaming = false;
          // if nothing is updating, close stream
          if (mediaSource && mediaSource.readyState === "open" && sourceBuffer && !sourceBuffer.updating && queue.length === 0) {
            try { mediaSource.endOfStream(); } catch {}
          }
        }
        if (j.error) {
          addMessage("ai", "Ø®Ø·Ø£", j.error);
        }
      } catch {}
      return;
    }

    // binary chunk
    appendMp3Chunk(new Uint8Array(evt.data));
  };

  ttsSocket.onclose = () => {};
  ttsSocket.onerror = () => {};
}

// Send text to TTS stream and autoplay
async function speak(text) {
  connectTTS();
  resetMediaSource();

  // (Important) browsers often allow autoplay only after a user gesture.
  // Recording/Stop counts as a gesture so autoplay typically works.
  audioEl.play().catch(() => { /* ignore */ });

  ttsSocket.send(JSON.stringify({
    text,
    voice_id: selected.voice_id
  }));
}

// ------------------------------
// Recording (MediaRecorder)
// ------------------------------
async function startRecording() {
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  chunks = [];

  mediaRecorder = new MediaRecorder(stream, { mimeType: "audio/webm" });

  mediaRecorder.ondataavailable = (e) => {
    if (e.data.size > 0) chunks.push(e.data);
  };

  mediaRecorder.onstop = async () => {
    // stop tracks
    stream.getTracks().forEach(t => t.stop());

    const blob = new Blob(chunks, { type: "audio/webm" });
    await handleAudio(blob);
  };

  mediaRecorder.start();
}

async function stopRecording() {
  if (mediaRecorder && mediaRecorder.state !== "inactive") {
    mediaRecorder.stop();
  }
}

// ------------------------------
// Pipeline: audio -> /stt -> /chat -> /tts(stream)
// ------------------------------
async function handleAudio(blob) {
  recState.textContent = "â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙØ±ÙŠØº...";
  recBtn.disabled = true;
  stopBtn.disabled = true;

  // 1) STT
  const fd = new FormData();
  fd.append("audio", blob, "audio.webm");

  let transcript = "";
  try {
    const r = await fetch("/stt", { method: "POST", body: fd });
    const j = await r.json();
    transcript = (j.text || "").trim();
  } catch (e) {
    addMessage("ai", "Ø®Ø·Ø£", "ÙØ´Ù„ Ø§Ù„ØªÙØ±ÙŠØº.");
    recState.textContent = "Ø¬Ø§Ù‡Ø²";
    recBtn.disabled = false;
    return;
  }

  if (!transcript) {
    addMessage("ai", "ØªÙ†Ø¨ÙŠÙ‡", "Ù„Ù… Ø£Ø³Ù…Ø¹ ÙƒÙ„Ø§Ù…Ø§Ù‹ ÙˆØ§Ø¶Ø­Ø§Ù‹. Ø­Ø§ÙˆÙ„ Ù…Ø¬Ø¯Ø¯Ø§Ù‹.");
    recState.textContent = "Ø¬Ø§Ù‡Ø²";
    recBtn.disabled = false;
    return;
  }

  addMessage("user", "Ø£Ù†Øª", transcript);

  // 2) Chat
  recState.textContent = "ğŸ’­ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯...";
  let reply = "";
  try {
    const r = await fetch("/chat", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        history,
        user_text: transcript,
        tutor_name: selected.tutor_name,
        voice_id: selected.voice_id,
      }),
    });
    const j = await r.json();
    reply = (j.reply || "").trim();
    history = j.history || history;
  } catch {
    addMessage("ai", "Ø®Ø·Ø£", "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.");
    recState.textContent = "Ø¬Ø§Ù‡Ø²";
    recBtn.disabled = false;
    return;
  }

  addMessage("ai", selected.tutor_name, reply);

  // 3) TTS stream autoplay
  recState.textContent = "ğŸ™ï¸ ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª...";
  await speak(reply);

  recState.textContent = "Ø¬Ø§Ù‡Ø²";
  recBtn.disabled = false;
}

// ------------------------------
// Init UI
// ------------------------------
function initVoices() {
  VOICES.forEach((v, idx) => {
    const opt = document.createElement("option");
    opt.value = String(idx);
    opt.textContent = v.label;
    voiceSelect.appendChild(opt);
  });

  voiceSelect.value = "0";
  setTutorUI();

  voiceSelect.addEventListener("change", () => {
    selected = VOICES[Number(voiceSelect.value)];
    setTutorUI();

    // production UX: changing voice resets session (fix duplicates, cache, etc.)
    history = [];
    chatEl.innerHTML = "";
    addMessage("ai", selected.tutor_name, `Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹! Ø£Ù†Ø§ ${selected.tutor_name}. Ù…Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø£Ù† Ù†ØªØ­Ø¯Ø« Ø¹Ù†Ù‡ Ø§Ù„ÙŠÙˆÙ…ØŸ`);
    speak(`Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹! Ø£Ù†Ø§ ${selected.tutor_name}. Ù…Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø£Ù† Ù†ØªØ­Ø¯Ø« Ø¹Ù†Ù‡ Ø§Ù„ÙŠÙˆÙ…ØŸ`);
  });
}

recBtn.addEventListener("click", async () => {
  recState.textContent = "ğŸ”´ ØªØ³Ø¬ÙŠÙ„...";
  recBtn.disabled = true;
  stopBtn.disabled = false;
  await startRecording();
});

stopBtn.addEventListener("click", async () => {
  recState.textContent = "â³ Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„...";
  stopBtn.disabled = true;
  await stopRecording();
});

newChatBtn.addEventListener("click", () => {
  history = [];
  chatEl.innerHTML = "";
  addMessage("ai", selected.tutor_name, `Ø¨Ø¯Ø£Ù†Ø§ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©. Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø£Ù† ØªØªØ­Ø¯Ø« Ø¹Ù†Ù‡ØŸ`);
  speak(`Ø¨Ø¯Ø£Ù†Ø§ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©. Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø£Ù† ØªØªØ­Ø¯Ø« Ø¹Ù†Ù‡ØŸ`);
});

(async function boot(){
  initVoices();
  await loadHealth();

  // First greeting (autoplay after user gesture might be blocked; still show text)
  addMessage("ai", selected.tutor_name, `Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹! Ø£Ù†Ø§ ${selected.tutor_name}. Ù…Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø£Ù† Ù†ØªØ­Ø¯Ø« Ø¹Ù†Ù‡ Ø§Ù„ÙŠÙˆÙ…ØŸ`);
})();